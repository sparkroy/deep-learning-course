{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hw2/small.txt') as f:\n",
    "    words_matrix = []\n",
    "    lines = f.readlines()\n",
    "    vocalubary = set()\n",
    "    labels = []\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        labels.append(int(words[0]))\n",
    "        words_matrix.append(words[1:])\n",
    "        for w in words[1:]:\n",
    "            vocalubary.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41924453/pytorch-how-to-use-dataloaders-for-custom-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'have', 'an', 'apple'], ['I', 'have', 'a', 'pen'], ['apple', 'pen']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I', 'a', 'an', 'apple', 'have', 'pen'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocalubary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(list(vocalubary))\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(words_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "bag_of_words_matrix = torch.zeros(n_samples, len(vocalubary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for lidx, line in enumerate(words_matrix):\n",
    "    if lidx % 500 == 0:\n",
    "        print(lidx)\n",
    "    indexes = le.transform(line)\n",
    "    for i in indexes:\n",
    "        bag_of_words_matrix[lidx][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0.],\n",
       "        [1., 1., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'a', 'an', 'apple', 'have', 'pen'], dtype='<U5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(bag_of_words_matrix, torch.IntTensor(labels))\n",
    "train_loader = data_utils.DataLoader(train, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1., 0., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 0., 0., 1., 1.]]), tensor([0, 1, 1], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s=words_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dummy_train = pd.get_dummies(list(vocalubary))\n",
    "dummy_test = pd.get_dummies(['ajfingfg','apple'])\n",
    "dummy_test = dummy_test.reindex(columns = dummy_train.columns, fill_value=0)\n",
    "torch.IntTensor(dummy_test.values.any(axis=0).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ajfingfg</th>\n",
       "      <th>apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ajfingfg  apple\n",
       "0         1      0\n",
       "1         0      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    #read in tokens\n",
    "    vocalubary = set()\n",
    "    with open(filename) as f:\n",
    "        words_matrix = []\n",
    "        lines = f.readlines()\n",
    "        labels = []\n",
    "        for l in lines:\n",
    "            words = l.split()\n",
    "            labels.append(int(words[0]))\n",
    "            words_matrix.append(words[1:])\n",
    "            for w in words[1:]:\n",
    "                vocalubary.add(w)\n",
    "    return vocalubary, words_matrix, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(vocalubary, words_matrix, labels):\n",
    "    le=preprocessing.LabelEncoder()\n",
    "    le.fit(list(vocalubary))\n",
    "    bag_of_words_matrix = torch.zeros(n_samples, len(vocalubary))\n",
    "    for lidx, line in enumerate(words_matrix):\n",
    "        if lidx % 500 == 0:\n",
    "            print(lidx)\n",
    "        indexes = le.transform(line)\n",
    "        for i in indexes:\n",
    "            bag_of_words_matrix[lidx][i] = 1\n",
    "    ds = data_utils.TensorDataset(bag_of_words_matrix, torch.IntTensor(labels))\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocalubary, words_matrix, labels=preprocess('hw2/small.txt')\n",
    "\n",
    "train_ds = encode(vocalubary, words_matrix, labels_dict[train_name])\n",
    "train_loader = data_utils.DataLoader(train_ds, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    #read in tokens\n",
    "    vocalubary = set()\n",
    "    with open(filename) as f:\n",
    "        words_matrix = []\n",
    "        lines = f.readlines()\n",
    "        labels = []\n",
    "        for l in lines:\n",
    "            words = l.split()\n",
    "            labels.append(int(words[0]))\n",
    "            words_matrix.append(words[1:])\n",
    "            for w in words[1:]:\n",
    "                vocalubary.add(w)\n",
    "    dummy_train = pd.get_dummies(list(vocalubary))\n",
    "    return dummy_train, vocalubary, words_matrix, labels\n",
    "\n",
    "def encode(dummy_train, words_matrix, labels):\n",
    "    bag_of_words_matrix = []\n",
    "    for lidx, line in enumerate(words_matrix):\n",
    "        if lidx % 500 == 0:\n",
    "            print(lidx)\n",
    "        dummy_test = pd.get_dummies(line)\n",
    "        dummy_test = dummy_test.reindex(columns = dummy_train.columns, fill_value=0)\n",
    "        bag_of_words_matrix.append(dummy_test.values.any(axis=0).astype('int'))\n",
    "    ds = data_utils.TensorDataset(torch.FloatTensor(bag_of_words_matrix), torch.LongTensor(labels))\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dummy_train, vocalubary, words_matrix, labels=preprocess('hw2/small.txt')\n",
    "\n",
    "train_ds = encode(dummy_train, words_matrix, labels)\n",
    "train_loader = data_utils.DataLoader(train_ds, batch_size=50, shuffle=True)\n",
    "\n",
    "_, _, words_matrix_t, labels_t=preprocess('hw2/small_test.txt')\n",
    "test_ds = encode(dummy_train, words_matrix_t, labels_t)\n",
    "test_loader = data_utils.DataLoader(test_ds, batch_size=50, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>a</th>\n",
       "      <th>an</th>\n",
       "      <th>apple</th>\n",
       "      <th>have</th>\n",
       "      <th>pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  a  an  apple  have  pen\n",
       "0  1  0   0      0     0    0\n",
       "1  0  1   0      0     0    0\n",
       "2  0  0   0      1     0    0\n",
       "3  0  0   1      0     0    0\n",
       "4  0  0   0      0     0    1\n",
       "5  0  0   0      0     1    0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0, 0, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 1, 0]], dtype=torch.int32), tensor([0, 1], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "for i in test_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1(nn.Module):\n",
    "    # You will implement a simple version of vgg11 (https://arxiv.org/pdf/1409.1556.pdf)\n",
    "    # Since the shape of image in CIFAR10 is 32x32x3, much smaller than 224x224x3, \n",
    "    # the number of channels and hidden units are decreased compared to the architecture in paper\n",
    "    def __init__(self, vocabulary_size):\n",
    "        super(model_1, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(vocabulary_size, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, net, criterion, optimizer, device):\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        start = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, (sentences, labels) in enumerate(trainloader):\n",
    "            sentences = sentences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass\n",
    "            outputs = net(sentences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "            #optimize the network\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                end = time.time()\n",
    "                print('[epoch %d, iter %5d] loss: %.3f eplased time %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100, end-start))\n",
    "                start = time.time()\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def test(testloader, net, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            sentences, labels = data\n",
    "            sentences = sentences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(sentences)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 1.]])\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 0., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 1.]])\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 0., 0., 1., 1.]])\n",
      "Finished Training\n",
      "tensor([[1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.]])\n",
      "Accuracy of the network on the 10000 test images: 50 %\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cpu')\n",
    "    train_name = 'hw2/small.txt'\n",
    "    test_name = 'hw2/small_test.txt'\n",
    "    dev_name = 'hw2/small_test.txt'\n",
    "    \n",
    "    dummy_train, vocalubary, words_matrix, labels=preprocess(train_name)\n",
    "\n",
    "    train_ds = encode(dummy_train, words_matrix, labels)\n",
    "    train_loader = data_utils.DataLoader(train_ds, batch_size=50, shuffle=True)\n",
    "\n",
    "    _, _, words_matrix_test, labels_test = preprocess(test_name)\n",
    "    test_ds = encode(dummy_train, words_matrix_test, labels_test)\n",
    "    test_loader = data_utils.DataLoader(test_ds, batch_size=50, shuffle=False)\n",
    "    \n",
    "    _, _, words_matrix_dev, labels_dev = preprocess(dev_name)\n",
    "    dev_ds = encode(dummy_train, words_matrix_dev, labels_dev)\n",
    "    dev_loader = data_utils.DataLoader(dev_ds, batch_size=50, shuffle=False)\n",
    "    \n",
    "    net = model_1(len(vocalubary)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    train(train_loader, net, criterion, optimizer, device)\n",
    "    test(test_loader, net, device)\n",
    "    \n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
